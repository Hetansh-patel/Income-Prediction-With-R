---
title: "R Notebook"
output: html_notebook
---

Importing Libraries

```{r}
options(scipen = 99)
library(ggplot2)
library(GGally)
library(rsample)    
library(caTools)
library(reshape2)
library(ggpubr)     
library(glmnet)
library(corrplot)
library(psych)
library(ggpubr)
library(ggcorrplot)
library(pROC)
library(caret)
library(rpart)        
library(rpart.plot)
library(plotrix)
library(e1071)
library(class)
library(neuralnet)
library(gbm)
library(randomForest)
library(xgboost)
```

```{r}
df = adult
```

```{r}
summary(df)
```

```{r}
colSums(is.na(df))
```

Theres a problem in our data. Na values are marked as "?". So we have to fix that first

```{r}
df[df == "?"] = NA
```

Now its showing our NA values

```{r}
colSums(is.na(df))
```

Every column that has NA values is char type. So even if we fill that values it would be miss leading rather than its better to delete that rows.

```{r}
df = na.omit(df)
```

```{r}
summary(df)
```
```{r}
print(sapply(df, class))



```

```{r}
correlation_plot(df)
```

```{r}
cat("Unique values in Workclass:\n\n")
unique(df$workclass)
cat('\n')

cat("Unique values in Education:\n\n")
unique(df$education)
cat('\n')

cat("Unique values in Marital Status:\n\n")
unique(df$marital.status)
cat('\n')

cat("Unique values in Occupation:\n\n")
unique(df$occupation)
cat('\n')

cat("Unique values in Relationship Status:\n\n")
unique(df$relationship)
cat('\n')

cat("Unique values in Race:\n\n")
unique(df$race)
cat('\n')

cat("Unique values in Native Country:\n\n")
unique(df$native.country)
cat('\n')

cat("Unique values in Income:\n")
unique(df$income)
```

```{r}
# Replace 'workclass' values in the existing dataframe
df$workclass <- ifelse(df$workclass == "Private", 1,
                       ifelse(df$workclass %in% c("State-gov", "Federal-gov", "Local-gov"), 2,
                       ifelse(df$workclass == "Without-pay", 4, 3)))

df$education <- ifelse(df$education %in% c("HS-grad", "Bachelors", "Prof-school"), 1,
                             ifelse(df$education == "Masters", 2,
                             ifelse(df$education == "Doctorate", 3, 4)))

df$marital.status <- ifelse(df$marital.status %in% c("Widowed", "Divorced", "Never-married", "Separated"), 1,
                                  ifelse(df$marital.status %in% c("Married-civ-spouse", "Married-AF-spouse", "Married-spouse-absent"), 2, NA))

df$relationship = NULL

df$race <- ifelse(df$race == "White", 1,
                      ifelse(df$race == "Black", 2,
                      ifelse(df$race %in% c("Asian-Pac-Islander", "Amer-Indian-Eskimo"), 3, 4)))

df$native.country <- ifelse(df$native.country %in% c(
    "United-States", "Canada", "Mexico", "Trinadad&Tobago", "South", "Puerto-Rico", "Honduras", "Cuba", "Nicaragua", "Dominican-Republic",
    "Guatemala", "El-Salvador", "Jamaica", "Ecuador", "Outlying-US(Guam-USVI-etc)", "Columbia", "Ecuador","Peru","Haiti"), 1,
  
  ifelse(df$native.country %in% c(
    "Greece", "Holand-Netherlands", "Poland", "England", "Germany", "Italy", "Ireland", "Hungary", "France", "Yugoslavia", "Portugal", "Scotland"), 2,
  
  ifelse(df$native.country %in% c(
    "Vietnam", "China", "India", "Taiwan", "Philippines", "Iran", "Japan", "Hong", "Cambodia", "Laos", "Thailand"), 3, NA)))


df$sex = ifelse(df$sex == "Male", 1,2)


df$income <- ifelse(df$income == "<=50K", 1, 
                           ifelse(df$income == ">50K", 2, NA))



```

```{r}
hours_breaks <- c(1, 40, 45,Inf)
hours_labels <- c(1, 2, 3)

# Create a new factor variable for age groups
df$hours.per.week <- cut(df$hours.per.week, breaks = hours_breaks, labels = hours_labels)


age_breaks <- c(17, 28, 37, 47,Inf)
age_labels <- c(1, 2, 3, 4)

# Create a new factor variable for age groups
df$age <- cut(df$age, breaks = age_breaks, labels = age_labels)

educationnum_breaks <- c(1, 9, 10, 13,Inf)
educationnum_labels <- c(1, 2, 3, 4)

# Create a new factor variable for age groups
df$education.num <- cut(df$education.num, breaks = educationnum_breaks, labels = educationnum_labels)



fnlwgt_breaks <- c(13769, 117627, 178425, 237628,Inf)
fnlwgt_labels <- c(1, 2, 3, 4)

# Create a new factor variable for age groups
df$fnlwgt <- cut(df$fnlwgt, breaks = fnlwgt_breaks, labels = fnlwgt_labels)



```

```{r}
df1 = df
```

```{r}
df1$Exec_managerial <- as.factor(df$occupation == "Exec-managerial")
df1$Prof_specialty <- as.factor(df$occupation == "Prof-specialty")
df1$Machine_op_inspct <- as.factor(df$occupation == "Machine-op-inspct")
df1$Tech_support <- as.factor(df$occupation == "Tech-support")
df1$Craft_repair <- as.factor(df$occupation == "Craft-repair")
df1$Transport_moving <- as.factor(df$occupation == "Transport-moving")
df1$Other_service <- as.factor(df$occupation == "Other-service")
df1$Adm_clerical <- as.factor(df$occupation == "Adm-clerical")
df1$Sales <- as.factor(df$occupation == "Sales")
df1$Farming_fishing <- as.factor(df$occupation == "Farming-fishing")
df1$Protective_serv <- as.factor(df$occupation == "Protective-serv")
df1$Handlers_cleaners <- as.factor(df$occupation == "Handlers-cleaners")
df1$Armed_Forces <- as.factor(df$occupation == "Armed-Forces")
df1$Priv_house_serv <- as.factor(df$occupation == "Priv-house-serv")

```

```{r}
df1$occupation = NULL
```

```{r}
correlation_plot(df1)
```

```{r}
df1$native.country = NULL
df1$race = NULL
```

Placing our income column to last

```{r}
df1 <- df1[, c(setdiff(names(df1), "income"), "income")]

```

```{r}
correlation_plot(df1)
```

```{r}
colnames(df1)
```

```{r}
ggplot(adult, aes(x = age)) +
  geom_histogram(fill = "skyblue", color = "black", bins = 30) + 
  labs(title = "Age Distribution", x = "Age", y = "Count") +
  theme_cleveland() +
  theme(plot.title = element_text(hjust = 0.5))  
```

```{r}
df1$workclass = as.factor(df1$workclass)

custom_labels_w = c(
  "1" = "Private",  # Replace "1" with the appropriate value
  "2" = "Goverment",  # Replace "2" with the appropriate value
  "3" = "Self Employed",  # Replace "3" with the appropriate value
  "4" = "Without Pay")

ggplot(df1, aes(x = workclass, fill = workclass, group = workclass)) +
  geom_bar(color = "black") +
  labs(title = "WorkClass Distribution", x = "Classes", y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_brewer(palette = "Set2") +
  scale_x_discrete(labels = custom_labels_w)
```

```{r}
df1$education = as.factor(df1$education)

custom_labels_e = c(
  "1" = "Bachelors Level",  # Replace "1" with the appropriate value
  "2" = "Masters",  # Replace "2" with the appropriate value
  "3" = "Doctorate",  # Replace "3" with the appropriate value
  "4" = "Others")

ggplot(df1, aes(x = education, fill = education, group = education)) +
  geom_bar(color = "black") +
  labs(title = "Education Distribution", x = "Classes", y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_brewer(palette = "Set1")+
  scale_x_discrete(labels = custom_labels_e)
  
```

```{r}
df1$marital.status = as.factor(df1$marital.status)

custom_labels_m = c(
  "1" = "Single", 
  "2" = "Married")

ggplot(df1, aes(x = marital.status, fill = marital.status, group = marital.status)) +
  geom_bar(color = "black") +
  labs(title = "Maritial Status Distribution", x = "Classes", y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_brewer(palette = "Set1") +
   scale_x_discrete(labels = custom_labels_m)
```

```{r}
# Assuming your dataset contains a column for gender
df1$sex = as.factor(df1$sex)
gender_counts = table(df1$sex)

# Create a 3D pie chart with labels and percentages, split from the middle
pie3D(gender_counts, main = "Gender Distribution", col = c("pink", "blue"), explode = 0.1)
legend("topright", legend = paste(names(gender_counts), "(", formatC(gender_counts / sum(gender_counts) * 100, format = "f", digits = 1), "%)"), fill = c("pink", "blue"))
```

Lets start building models

```{r}
summary(df1)
```

Lets first convert factors to numeric

```{r}
df1$workclass = as.factor(df1$workclass)
df1$education = as.factor(df1$education)
df1$marital.status = as.factor(df1$marital.status)
df1$income= as.factor(df1$income)
df1 = na.omit(df1)
```

```{r}
summary(df1)
```

```{r}

# Set the number of neighbors (k) - you can adjust this value
#k <- 10

# Create a KNN model
#knn_model <- knn(train = df_train, test = df_test, cl = df_train$income, k = k)

#y_pred_train = predict(knn_model,newdata=df_train,type = 'class' )
#y_pred_test = predict(knn_model,newdata=df_test, type = 'class')

#df_train_results = data.frame(y_pred_train,df_train$income)
#confusionMatrix(table(df_train_results))

#df_test_results = data.frame(y_pred_test,df_test$income)
#confusionMatrix(table(df_test_results))




```


```{r}
#nn_model <- neuralnet(income ~. , data = df_train, hidden = c(10, 10))

#y_pred_train = predict(nn_model,newdata=df_train,type = 'class' )
#y_pred_test = predict(nn_model,newdata=df_test, type = 'class')

#df_train_results = data.frame(y_pred_train,df_train$income)
#confusionMatrix(table(df_train_results))

#df_test_results = data.frame(y_pred_test,df_test$income)
#confusionMatrix(table(df_test_results))
```


```{r}
# Initialize an empty data frame to store results
results_df1 <- data.frame(
  Dataset_Number = integer(),
  Model = character(),
  Train_Accuracy = numeric(),
  Test_Accuracy = numeric()
)

# Define a list of models
models <- list(
  Decision_Tree = rpart,
  Random_Forest = randomForest,
  Support_Vector = svm,
  Naive_Bayes = naiveBayes
)

# Create a list to store datasets
dataset_list <- list()

# Loop through models
for (model_name in names(models)) {
  model <- models[[model_name]]
  
  for (i in 1:10) {
    # Split the data
    data = split_show(df1, 0.6)
    df_train = data[[2]]
    df_test = data[[3]]
    
    # Store the dataset in the dataset_list
    dataset_list[[i]] <- list(df_train = df_train, df_test = df_test)
    
    # Fit the model
    if (model_name == "Random_Forest") {
      model <- randomForest(income ~ ., data = df_train, ntree = 20)
    } else if (model_name == "Support_Vector") {
      model <- svm(income ~ ., data = df_train, kernel = "linear")
    } else if (model_name == "Naive_Bayes") {
      model <- naiveBayes(income ~ ., data = df_train)
    } else {
      model <- rpart(income ~ ., data = df_train, method = 'class', cp = -1)
    }
    
    # Make predictions on the test data
    y_pred_train <- predict(model, newdata = df_train, type = 'class')
    y_pred_test <- predict(model, newdata = df_test, type = 'class')
    
    # Calculate train and test accuracy
    train_accuracy <- sum(y_pred_train == df_train$income) / nrow(df_train)
    test_accuracy <- sum(y_pred_test == df_test$income) / nrow(df_test)
    
    # Add results to results_df
    results_df1 <- rbind(results_df1, data.frame(
      Dataset_Number = i,
      Model = model_name,
      Train_Accuracy = train_accuracy,
      Test_Accuracy = test_accuracy
    ))
  }
}

# Display the results
#print(results_df1)


```

```{r}
results_df_logistic <- data.frame(
  Dataset_Number = integer(),
  Train_Accuracy = numeric(),
  Test_Accuracy = numeric()
)

# Create a list to store datasets
dataset_list_logistic <- list()

for (i in 1:10) {
  # Split the data
  data = split_show(df1, 0.6)
  df_train = data[[2]]
  df_test = data[[3]]
  
  # Store the dataset in the dataset_list
  dataset_list_logistic[[i]] <- list(df_train = df_train, df_test = df_test)
  
  # Fit the logistic regression model
  logistic_model <- glm(income ~ ., family = binomial, data = df_train)
  y_pred_train <- predict(logistic_model, newdata = df_train, type = "response")
  y_pred_test <- predict(logistic_model, newdata = df_test, type = "response")
  
  threshold <- 0.5
  y_pred_train_class <- ifelse(y_pred_train >= threshold, 2, 1)
  y_pred_test_class <- ifelse(y_pred_test >= threshold, 2, 1)
  
  # Calculate train and test accuracy
  train_accuracy <- sum(y_pred_train_class == df_train$income) / nrow(df_train)
  test_accuracy <- sum(y_pred_test_class == df_test$income) / nrow(df_test)
  
  # Add results to results_df_logistic
  results_df_logistic <- rbind(results_df_logistic, data.frame(
    Dataset_Number = i,
    Model = "Logistic_Regression",
    Train_Accuracy = train_accuracy,
    Test_Accuracy = test_accuracy
  ))
}

# Display the results
print(results_df_logistic)
```

```{r}
results_df_final1 <- rbind(results_df1,results_df_logistic)
```

```{r}
results_df_final1
```


```{r}
# Extract the row with the maximum test accuracy
results_df_final1[which.max(results_df_final1$Test_Accuracy), ]

```

```{r}
max_test_accuracy <- aggregate(Test_Accuracy ~ Model, data = results_df_final1, FUN = max)

bar_colors <- c("lightblue", "firebrick", "lightyellow", "darkblue", "seagreen")

# Create a bar plot with different colors for each bar
ggplot(data = max_test_accuracy, aes(x = Model, y = Test_Accuracy, fill = Model)) +
  geom_bar(stat = "identity", color = "black") +  # Set the outline color to black
  scale_fill_manual(values = bar_colors) +  # Assign custom colors to bars
  geom_text(aes(label = round(Test_Accuracy, 2)), vjust = -0.5, size = 3.5) +  # Add text labels
  labs(title = "Maximum Test Accuracy for Each Model",
       x = "Model",
       y = "Max Test Accuracy") +
  theme_minimal() +
  theme(legend.title = element_blank())
```
```{r}
ggplot(data = results_df_final1, aes(x = Train_Accuracy, y = Test_Accuracy)) +
  geom_point() +
  labs(title = "Scatter Plot of Train Accuracy vs. Test Accuracy",
       x = "Train Accuracy",
       y = "Test Accuracy") +
  theme_minimal()
```


##Second try without occupation

```{r}
df2 = df1
```

```{r}
df2$Exec_managerial = NULL
df2$Prof_specialty= NULL
df2$Machine_op_inspct= NULL
df2$Transport_moving= NULL
df2$Craft_repair= NULL
df2$Handlers_cleaners= NULL
df2$Farming_fishing= NULL
df2$Adm_clerical= NULL
df2$Other_service= NULL
df2$Adm_clerical = NULL
df2$Sales =NULL
df2$Farming_fishing = NULL
df2$Protective_serv = NULL
df2$Handlers_cleaners = NULL
df2$Armed_Forces = NULL
df2$Priv_house_serv = NULL
df2$Tech_support = NULL
df2$fnlwgt = NULL
df2$education.num = NULL
df2$marital.status = NULL
df2$sex = NULL
df2$race = NULL
#df2$capital.gain = NULL
#df2$capital.loss = NULL
```

```{r}
df2
```

```{r}
#df2$capital.gain = as.factor(df2$capital.gain)
#df2$capital.loss = as.factor(df2$capital.loss)
```

```{r}
results_df2 <- data.frame(
  Dataset_Number = integer(),
  Model = character(),
  Train_Accuracy = numeric(),
  Test_Accuracy = numeric()
)

# Define a list of models
models <- list(
  Decision_Tree = rpart,
  Random_Forest = randomForest,
  Support_Vector = svm,
  Naive_Bayes = naiveBayes
)

# Create a list to store datasets
dataset_list2 <- list()

# Loop through models
for (model_name in names(models)) {
  model <- models[[model_name]]
  
  for (i in 1:10) {
    # Split the data
    data = split_show(df2, 0.6)
    df_train = data[[2]]
    df_test = data[[3]]
    
    # Store the dataset in the dataset_list
    dataset_list2[[i]] <- list(df_train = df_train, df_test = df_test)
    
    # Fit the model
    if (model_name == "Random_Forest") {
      model <- randomForest(income ~ ., data = df_train, ntree = 20)
    } else if (model_name == "Support_Vector") {
      model <- svm(income ~ ., data = df_train, kernel = "linear")
    } else if (model_name == "Naive_Bayes") {
      model <- naiveBayes(income ~ ., data = df_train)
    } else {
      model <- rpart(income ~ ., data = df_train, method = 'class', cp = -1)
    }
    
    # Make predictions on the test data
    y_pred_train <- predict(model, newdata = df_train, type = 'class')
    y_pred_test <- predict(model, newdata = df_test, type = 'class')
    
    # Calculate train and test accuracy
    train_accuracy <- sum(y_pred_train == df_train$income) / nrow(df_train)
    test_accuracy <- sum(y_pred_test == df_test$income) / nrow(df_test)
    
    # Add results to results_df
    results_df2 <- rbind(results_df2, data.frame(
      Dataset_Number = i,
      Model = model_name,
      Train_Accuracy = train_accuracy,
      Test_Accuracy = test_accuracy
    ))
  }
}

# Display the results
#print(results_df2)
```

#FOr df2
```{r}
results_df_logistic2 <- data.frame(
  Dataset_Number = integer(),
  Train_Accuracy = numeric(),
  Test_Accuracy = numeric()
)

# Create a list to store datasets
dataset_list_logistic2 <- list()

for (i in 1:10) {
  # Split the data
  data = split_show(df2, 0.6)
  df_train = data[[2]]
  df_test = data[[3]]
  
  # Store the dataset in the dataset_list
  dataset_list_logistic2[[i]] <- list(df_train = df_train, df_test = df_test)
  
  # Fit the logistic regression model
  logistic_model <- glm(income ~ ., family = binomial, data = df_train)
  y_pred_train <- predict(logistic_model, newdata = df_train, type = "response")
  y_pred_test <- predict(logistic_model, newdata = df_test, type = "response")
  
  threshold <- 0.5
  y_pred_train_class <- ifelse(y_pred_train >= threshold, 2, 1)
  y_pred_test_class <- ifelse(y_pred_test >= threshold, 2, 1)
  
  # Calculate train and test accuracy
  train_accuracy <- sum(y_pred_train_class == df_train$income) / nrow(df_train)
  test_accuracy <- sum(y_pred_test_class == df_test$income) / nrow(df_test)
  
  # Add results to results_df_logistic
  results_df_logistic2 <- rbind(results_df_logistic2, data.frame(
    Dataset_Number = i,
    Model = "Logistic_Regression",
    Train_Accuracy = train_accuracy,
    Test_Accuracy = test_accuracy
  ))
}

# Display the results
print(results_df_logistic2)

```

```{r}
results_df_final2 <- rbind(results_df2,results_df_logistic2)
```

```{r}
results_df2[which.max(results_df2$Test_Accuracy), ]
```


```{r}
max_test_accuracy <- aggregate(Test_Accuracy ~ Model, data = results_df_final2, FUN = max)

bar_colors <- c("lightblue", "firebrick", "lightyellow", "darkblue", "seagreen")

# Create a bar plot with different colors for each bar
ggplot(data = max_test_accuracy, aes(x = Model, y = Test_Accuracy, fill = Model)) +
  geom_bar(stat = "identity", color = "black") +  # Set the outline color to black
  scale_fill_manual(values = bar_colors) +  # Assign custom colors to bars
  geom_text(aes(label = round(Test_Accuracy, 2)), vjust = -0.5, size = 3.5) +  # Add text labels
  labs(title = "Maximum Test Accuracy for Each Model",
       x = "Model",
       y = "Max Test Accuracy") +
  theme_minimal() +
  theme(legend.title = element_blank())
```


```{r}
ggplot(data = results_df_final2, aes(x = Train_Accuracy, y = Test_Accuracy)) +
  geom_point() +
  labs(title = "Scatter Plot of Train Accuracy vs. Test Accuracy",
       x = "Train Accuracy",
       y = "Test Accuracy") +
  theme_minimal()
```

